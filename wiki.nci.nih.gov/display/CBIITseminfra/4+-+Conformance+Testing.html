Services specifications developed by NCI and the community have to be testable to ensure that the implementation conforms to the specification.

Conformance testing leverages the artifact and service metadata to validate that an implementation adequately addresses the requirements stated in the service specification. An example of service requirement is the ability to specify a response time in the specification (design time) and validate that this response time is valid for an implementation of the service. Additional test points include but are not limited to binding to specific terminologies and domain models.

Capabilities related to Conformance Testing within the Semantic Infrastructure are summarized as:
<ul>
  <li>
    Testing for Conformance, including a Service-Oriented Architecture (SOA) Testing Environment and semantic validation of interoperability
  </li>
</ul>
Conformance testing allows both CBIIT and other HL7 SAIF adopters to validate specifications.


Functional Profile Group
<ul>
  <li>
    <a href="https://wiki.nci.nih.gov/pages/viewpage.action?pageId=32769316" rel="nofollow">
      4.1 - Create Conformance Statements
    </a>
  </li>
  <li>
    <a href="https://wiki.nci.nih.gov/pages/viewpage.action?pageId=32769318" rel="nofollow">
      4.2 - Search and Access Conformance Statements
    </a>
    Conformance testing leverages the artifact and service metadata to validate that an implementation adequately addresses the requirements stated in the service specification. An example of service requirement is the ability to specify a response time in the specification (design time) and validate that this response time is valid for an implementation of the service. Additional test points include but are not limited to binding to specific terminologies and domain models.
    <ul>
      <li>
        <a href="https://wiki.nci.nih.gov/pages/viewpage.action?pageId=32769430" rel="nofollow">
          4.2.1 - Conformance Analysis
        </a>
        Provides search and access for conformance statements associated with design models and run-time artifacts
      </li>
    </ul>
  </li>
  <li>
    <a href="https://wiki.nci.nih.gov/pages/viewpage.action?pageId=32769320" rel="nofollow">
      4.3 - Test for Conformance
    </a>
    Testing for SOA combines the typical challenges of software testing and certification with the additional needs of accommodating the distributed nature of the resources, the greater access of a more unbounded consumer population, and the desired flexibility to create new solutions from existing components over which the solution developer has little if any control. The purpose of testing is to demonstrate a required level of reliability, correctness, and effectiveness that enable prospective consumers to have adequate confidence in using a service.
    <ul>
      <li>
        <a href="https://wiki.nci.nih.gov/pages/viewpage.action?pageId=32769432" rel="nofollow">
          4.3.1 - SOA Testing
        </a>
        Testing for SOA combines the typical challenges of software testing and certification with the additional needs of accommodating the distributed nature of the resources, the greater access of a more unbounded consumer population, and the desired flexibility to create new solutions from existing components over which the solution developer has little if any control. The purpose of testing is to demonstrate a required level of reliability, correctness, and effectiveness that enable prospective consumers to have adequate confidence in using a service. Adequacy is defined by the consumer based on the consumer&#39;s needs and context of use. Absolute correctness and completeness cannot be proven by testing; however, for SOA, it is critical for the prospective consumer to know what testing has been performed, how it has been performed, and what were the results.
      </li>
      <li>
        <a href="https://wiki.nci.nih.gov/pages/viewpage.action?pageId=32769434" rel="nofollow">
          4.3.2 - Validate
        </a>
        Conformance testing leverages the artifact and service metadata to validate that an implementation adequately addresses the requirements stated in the service specification. An example of service requirement is the ability to specify a response time in the specification (design time) and validate that this response time is valid for an implementation of the service. Additional test points include but are not limited to binding to specific terminologies and domain models.
      </li>
    </ul>
  </li>
</ul>